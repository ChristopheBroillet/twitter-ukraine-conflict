{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network baseline\n",
    "\n",
    "The original baseline of our network was taken from *Kaggle* and is available at\n",
    "[https://www.kaggle.com/datasets/bwandowando/ukraine-russian-crisis-twitter-dataset-1-2-m-rows](https://www.kaggle.com/datasets/bwandowando/ukraine-russian-crisis-twitter-dataset-1-2-m-rows). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"./.env.local\")\n",
    "import os\n",
    "BEARER_TOKEN = os.getenv(\"BEARER_TOKEN1\")\n",
    "# https://docs.tweepy.org/en/stable/client.html\n",
    "import tweepy\n",
    "client = tweepy.Client(BEARER_TOKEN, wait_on_rate_limit=True)\n",
    "from pathlib import Path\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of the Kaggle dataset\n",
    "\n",
    "* Filter to only keep english\n",
    "* Only keep relevant columns for our analysis: userid, tweetid, text, hashtags columns\n",
    "* Delete duplicate\n",
    "* Create a sample of the dataset (10k per each day)\n",
    "    * The sample is saved under the csvdataframes folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating folders\")\n",
    "Path.mkdir(Path(\"csvdataframes\"), exist_ok=True)\n",
    "Path.mkdir(Path(\"edgelists\"), exist_ok=True)\n",
    "Path.mkdir(Path(\"csvdataframes_wOgIds\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preprocessing the data\")\n",
    "for idx, day in enumerate(Path(\"dataset\").iterdir()):\n",
    "    full_dataset = pd.read_csv(day, compression='gzip', low_memory=False)\n",
    "    df_en = full_dataset[full_dataset['language']=='en']\n",
    "    df_en_filteted = df_en[[\"userid\", \"tweetid\", \"text\", \"hashtags\"]]\n",
    "    df_no_duplicate = df_en_filteted.drop_duplicates(subset='text', keep='first')\n",
    "    df_sampled = df_no_duplicate.sample(10000)\n",
    "    df_sampled.to_csv(Path(\"csvdataframes\") / f\"day_{idx}.csv\")\n",
    "    print(\".\", end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve original tweet id\n",
    "\n",
    "Because the baseline dataset may contain retweet, we need to get the original\n",
    "tweet in order to retrieve the list of people who liked and retweeted the tweet.\n",
    "The sample will be augmented with the original tweet id and saved under the csvdataframes_wOgIds folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(ids):\n",
    "    tweets = client.get_tweets(ids=ids, expansions=['referenced_tweets.id', 'referenced_tweets.id.author_id'])\n",
    "    return tweets\n",
    "\n",
    "\n",
    "def get_original_tweets_ids(ids):\n",
    "    ids_list = ids[\"tweetid\"].tolist()\n",
    "    tweets = get_tweets(ids_list)\n",
    "    return_df = pd.DataFrame(columns=[\"author_id\", \"original_tweet_id\"])\n",
    "    if not tweets.data:\n",
    "        return None, False\n",
    "    for tweet in tweets.data:\n",
    "        referenced_tweet = tweet.get('referenced_tweets')\n",
    "        original_author = tweet.get('author_id')\n",
    "        original_tweet_id = referenced_tweet[0].id if referenced_tweet else tweet.id\n",
    "        return_df = pd.concat([return_df, pd.DataFrame({\n",
    "            \"author_id\": [original_author],\n",
    "            \"original_tweet_id\": [original_tweet_id]\n",
    "        })], ignore_index=True)\n",
    "    return_df['Unnamed: 0'] = ids['Unnamed: 0']\n",
    "    return return_df, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By batch of 100 Tweets, get the original Tweet ID\n",
    "for idx, file in enumerate(Path(\"csvdataframes\").iterdir()):\n",
    "    print(file)\n",
    "    df = pd.read_csv(file)\n",
    "    # temp df to store original tweet ids\n",
    "    temp_df = pd.DataFrame()\n",
    "    # split df by 100\n",
    "    for i in range(0, len(df), 100):\n",
    "        print(f\"{file} Iteration {i}-{i+100} / {len(df)}\")\n",
    "        df_100 = df[i:i+100]\n",
    "        original_tweet_ids_df, empty_check = get_original_tweets_ids(df_100)\n",
    "        if not empty_check:\n",
    "            continue\n",
    "        temp_df = pd.concat(\n",
    "            [temp_df, original_tweet_ids_df], ignore_index=True)\n",
    "\n",
    "    if temp_df.empty:\n",
    "        continue\n",
    "    df = pd.merge(df, temp_df, on=\"Unnamed: 0\")\n",
    "    df.to_csv(Path(f\"csvdataframes_wOgIds/day_{idx}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve likers and retweeters\n",
    "\n",
    "Retrieve likers and retweeters based on the original tweet id and create a\n",
    "edgelist. The result is saved under the edgelists folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_retweeters from one id and one pagination token\n",
    "def get_retweeters(id, pagination_token=None):\n",
    "    print(\".\", end='', flush=True)\n",
    "    retweeters = client.get_retweeters(id, pagination_token=pagination_token)\n",
    "    next_token = retweeters.meta.get('next_token')\n",
    "\n",
    "    if not retweeters.data:\n",
    "        return None, None\n",
    "\n",
    "    retweeter_ids = [retweeter.id for retweeter in retweeters.data]\n",
    "    return retweeter_ids, next_token\n",
    "\n",
    "\n",
    "\n",
    "# get_all_retweeters from one id\n",
    "def get_all_retweeters(id):\n",
    "    retweeter_ids = []\n",
    "    next_token = None\n",
    "    while True:\n",
    "        retweeter_ids_, next_token = get_retweeters(id, pagination_token=next_token)\n",
    "        if retweeter_ids_ is None:\n",
    "            break\n",
    "        retweeter_ids += retweeter_ids_\n",
    "    return retweeter_ids\n",
    "\n",
    "\n",
    "def get_linkin_users(id, pagination_token=None):\n",
    "    print(\".\", end='', flush=True)\n",
    "    retweeters = client.get_liking_users(id, pagination_token=pagination_token)\n",
    "    next_token = retweeters.meta.get('next_token')\n",
    "\n",
    "    if not retweeters.data:\n",
    "        return None, None\n",
    "\n",
    "    retweeter_ids = [retweeter.id for retweeter in retweeters.data]\n",
    "    return retweeter_ids, next_token\n",
    "\n",
    "\n",
    "def get_all_linkin_users(id):\n",
    "    retweeter_ids = []\n",
    "    next_token = None\n",
    "    while True:\n",
    "        retweeter_ids_, next_token = get_linkin_users(id, pagination_token=next_token)\n",
    "        if retweeter_ids_ is None:\n",
    "            break\n",
    "        retweeter_ids += retweeter_ids_\n",
    "    return retweeter_ids\n",
    "\n",
    "\n",
    "def create_retweeters_edgelist():\n",
    "    print(\"Creating edgelist for retweets\")\n",
    "    for idx, file in enumerate(Path(\"csvdataframes_wOgIds\").iterdir()):\n",
    "        edgelists_df = pd.DataFrame(columns=[\"user_id\", \"author_id\"])\n",
    "        print(file)\n",
    "        df = pd.read_csv(file)\n",
    "        \n",
    "        for tweetId, author_id in zip(df['original_tweet_id'], df['author_id']):\n",
    "            print(tweetId, end='')\n",
    "            retweeter_ids = get_all_retweeters(tweetId)\n",
    "            retweeter_ids_df = pd.DataFrame(retweeter_ids, columns=[\"user_id\"])\n",
    "            retweeter_ids_df.insert(1, \"author_id\", author_id)\n",
    "            edgelists_df = pd.concat([edgelists_df, retweeter_ids_df], ignore_index=True)\n",
    "            print(\"Done\")\n",
    "\n",
    "        edgelists_df.to_csv(Path(f\"edgelists/retweeters_{idx}.csv\"), index=False)\n",
    "\n",
    "    \n",
    "def create_liking_edgelist():\n",
    "    print(\"Creating edgelist for likes\")\n",
    "    for idx, file in enumerate(Path(\"csvdataframes_wOgIds\").iterdir()):\n",
    "        edgelists_df = pd.DataFrame(columns=[\"user_id\", \"author_id\"])\n",
    "        print(file)\n",
    "        df = pd.read_csv(file)\n",
    "        for tweetId, author_id in zip(df['original_tweet_id'], df['author_id']):\n",
    "            print(tweetId, end='')\n",
    "            liker_ids = get_all_linkin_users(tweetId)\n",
    "            liker_ids_df = pd.DataFrame(liker_ids, columns=[\"user_id\"])\n",
    "            liker_ids_df.insert(1, \"author_id\", author_id)\n",
    "            edgelists_df = pd.concat([edgelists_df, liker_ids_df], ignore_index=True)\n",
    "            print(\"Done\")\n",
    "\n",
    "        edgelists_df.to_csv(Path(f\"edgelists/liking_{idx}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_retweeters_edgelist()\n",
    "create_liking_edgelist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
