{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network baseline\n",
    "\n",
    "The original baseline of our network was taken from kaggle and is available at\n",
    "[https://www.kaggle.com/datasets/bwandowando/ukraine-russian-crisis-twitter-dataset-1-2-m-rows](https://www.kaggle.com/datasets/bwandowando/ukraine-russian-crisis-twitter-dataset-1-2-m-rows). \n",
    "\n",
    "The baseline is saved under the dataset folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"./.env.local\")\n",
    "import os\n",
    "BEARER_TOKEN = os.getenv(\"BEARER_TOKEN1\")\n",
    "# https://docs.tweepy.org/en/stable/client.html\n",
    "import tweepy\n",
    "client = tweepy.Client(BEARER_TOKEN, wait_on_rate_limit=True)\n",
    "from pathlib import Path\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of the Kaggle dataset\n",
    "\n",
    "* Filter to only keep english\n",
    "* Only keep relevant columns for our analysis: userid, tweetid, text, hashtags columns\n",
    "* Delete duplicate\n",
    "* Create a sample of the dataset \n",
    "    * The sample is saved under the csvdataframes folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating folders\")\n",
    "Path.mkdir(Path(\"csvdataframes\"), exist_ok=True)\n",
    "Path.mkdir(Path(\"edgelists\"), exist_ok=True)\n",
    "Path.mkdir(Path(\"csvdataframes_wOgIds\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preprocessing the data\")\n",
    "for idx, day in enumerate(Path(\"dataset\").iterdir()):\n",
    "    full_dataset = pd.read_csv(day, compression='gzip', low_memory=False)\n",
    "    df_en = full_dataset[full_dataset['language']=='en']\n",
    "    df_en_filteted = df_en[[\"userid\", \"tweetid\", \"text\", \"hashtags\"]]\n",
    "    df_no_duplicate = df_en_filteted.drop_duplicates(subset='text', keep='first')\n",
    "    df_sampled = df_no_duplicate.sample(10000)\n",
    "    df_sampled.to_csv(Path(\"csvdataframes\") / f\"day_{idx}.csv\")\n",
    "    print(\".\", end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve original tweet id\n",
    "\n",
    "Because the baseline dataset may contain retweet, we need to get the original\n",
    "tweet in order to retrieve the list of people who liked and retweeted the tweet.\n",
    "The sample will be augmented with the original tweet id and saved under the csvdataframes_wOgIds folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(ids):\n",
    "    tweets = client.get_tweets(ids=ids, expansions=['referenced_tweets.id', 'referenced_tweets.id.author_id'])\n",
    "    return tweets\n",
    "\n",
    "def get_original_tweets_ids(ids):\n",
    "    # convert ids to list\n",
    "    ids_list = ids[\"tweetid\"].tolist()\n",
    "    tweets = get_tweets(ids_list)\n",
    "    # create df with columns original_tweet_id and author_id\n",
    "    return_df = pd.DataFrame(columns=[\"author_id\", \"original_tweet_id\", \"tweetid\"])\n",
    "    if not tweets.data: return None, False\n",
    "    for tweet in tweets.data:\n",
    "        referenced_tweet = tweet.get('referenced_tweets')\n",
    "        original_author = tweet.get('author_id')\n",
    "        original_tweet_id = referenced_tweet[0].id if referenced_tweet else tweet.id\n",
    "        # concat to df\n",
    "        return_df = pd.concat([return_df, pd.DataFrame({\"author_id\": original_author, \"original_tweet_id\": original_tweet_id, \"tweetid\": tweet.id})], ignore_index=True)\n",
    "    return return_df, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, file in enumerate(Path(\"csvdataframes\").iterdir()):\n",
    "    print(file)\n",
    "    df = pd.read_csv(file)\n",
    "    df = df.sample(n=500)\n",
    "    # temp df to store original tweet ids\n",
    "    temp_df = pd.DataFrame()\n",
    "    # split df by 100 \n",
    "    for i in range(0, len(df), 100):\n",
    "        print(f\"{file} Iteration {i}-{i+100} / {len(df)}\")\n",
    "        df_100 = df[i:i+100]\n",
    "        original_tweet_ids_df, empty_check = get_original_tweets_ids(df_100)\n",
    "        if not empty_check: continue\n",
    "        # concat temp_df and original_tweet_ids_df\n",
    "        temp_df = pd.concat([temp_df, original_tweet_ids_df], ignore_index=True)\n",
    "    # Merge temp_df with df\n",
    "    if temp_df.empty: continue\n",
    "    df = pd.merge(df, temp_df, on=\"tweetid\")\n",
    "    # save df to csv\n",
    "    df.to_csv(Path(f\"csvdataframes_wOgIds_test/day_{idx}.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve likers and retweeters\n",
    "\n",
    "Retrieve likers and retweeters based on the original tweet id and create a\n",
    "edgelist. The result is saved under the edgelists folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_retweeters from 1 id and 1 pagination token\n",
    "def get_retweeters(id, pagination_token=None):\n",
    "    print(\".\", end='', flush=True)\n",
    "    retweeters = client.get_retweeters(id, pagination_token=pagination_token)\n",
    "    next_token = retweeters.meta.get('next_token')\n",
    "\n",
    "    if not retweeters.data:\n",
    "        return None, None\n",
    "\n",
    "    # return list of user ids\n",
    "    retweeter_ids = [retweeter.id for retweeter in retweeters.data]\n",
    "    return retweeter_ids, next_token\n",
    "\n",
    "# get_all_retweeters from 1 id\n",
    "def get_all_retweeters(id):\n",
    "    retweeter_ids = []\n",
    "    next_token = None\n",
    "    while True:\n",
    "        retweeter_ids_, next_token = get_retweeters(id, pagination_token=next_token)\n",
    "        if retweeter_ids_ is None:\n",
    "            break\n",
    "        retweeter_ids += retweeter_ids_\n",
    "    return retweeter_ids\n",
    "\n",
    "def get_linkin_users(id, pagination_token=None):\n",
    "    print(\".\", end='', flush=True)\n",
    "    retweeters = client.get_liking_users(id, pagination_token=pagination_token)\n",
    "    next_token = retweeters.meta.get('next_token')\n",
    "\n",
    "    if not retweeters.data:\n",
    "        return None, None\n",
    "\n",
    "    # return list of user ids\n",
    "    retweeter_ids = [retweeter.id for retweeter in retweeters.data]\n",
    "    return retweeter_ids, next_token\n",
    "\n",
    "def get_all_linkin_users(id):\n",
    "    retweeter_ids = []\n",
    "    next_token = None\n",
    "    while True:\n",
    "        retweeter_ids_, next_token = get_linkin_users(id, pagination_token=next_token)\n",
    "        if retweeter_ids_ is None:\n",
    "            break\n",
    "        retweeter_ids += retweeter_ids_\n",
    "    return retweeter_ids\n",
    "\n",
    "def create_retweeters_edgelist():\n",
    "    # read csv files from csvdataframes_wOgIds folder\n",
    "    for idx, file in enumerate(Path(\"csvdataframes_wOgIds\").iterdir()):\n",
    "        # create empty edgelists df with column retweeter_id and tweet_id\n",
    "        edgelists_df = pd.DataFrame(columns=[\"user_id\", \"author_id\"])\n",
    "        print(file)\n",
    "        df = pd.read_csv(file)\n",
    "        \n",
    "        for tweetId, author_id in zip(df['original_tweet_id'], df['author_id']):\n",
    "            print(tweetId, end='')\n",
    "            retweeter_ids = get_all_retweeters(tweetId)\n",
    "            # convert to df\n",
    "            retweeter_ids_df = pd.DataFrame(retweeter_ids, columns=[\"user_id\"])\n",
    "            # add tweetId to df\n",
    "            retweeter_ids_df.insert(1, \"author_id\", author_id)\n",
    "            # concat edgelists_df and retweeter_ids_df\n",
    "            edgelists_df = pd.concat([edgelists_df, retweeter_ids_df], ignore_index=True)\n",
    "            print(\"Done\")\n",
    "        # save df to csv\n",
    "        edgelists_df.to_csv(Path(f\"edgelists/retweeters_{idx}.csv\"), index=False)\n",
    "\n",
    "    # # save edgelists_df to csv\n",
    "    # edgelists_df.to_csv(Path(f\"edgelists/retweeters.csv\"), index=False)\n",
    "\n",
    "    # return edgelists_df\n",
    "\n",
    "    \n",
    "def create_liking_edgelist():\n",
    "    # read csv files from csvdataframes_wOgIds folder\n",
    "    for idx, file in enumerate(Path(\"csvdataframes_wOgIds\").iterdir()):\n",
    "         # create empty edgelists df with column liker_id and tweet_id\n",
    "        edgelists_df = pd.DataFrame(columns=[\"user_id\", \"author_id\"])\n",
    "        print(file)\n",
    "        df = pd.read_csv(file)\n",
    "        for tweetId, author_id in zip(df['original_tweet_id'], df['author_id']):\n",
    "            print(tweetId, end='')\n",
    "            liker_ids = get_all_linkin_users(tweetId)\n",
    "            # convert to df\n",
    "            liker_ids_df = pd.DataFrame(liker_ids, columns=[\"user_id\"])\n",
    "            # add tweetId to df\n",
    "            liker_ids_df.insert(1, \"author_id\", author_id)\n",
    "            # concat edgelists_df and liker_ids_df\n",
    "            edgelists_df = pd.concat([edgelists_df, liker_ids_df], ignore_index=True)\n",
    "            print(\"Done\")\n",
    "        # save df to csv\n",
    "        edgelists_df.to_csv(Path(f\"edgelists/liking_{idx}.csv\"), index=False)\n",
    "\n",
    "    # # save edgelists_df to csv\n",
    "    # edgelists_df.to_csv(Path(f\"edgelists/liking.csv\"), index=False)\n",
    "\n",
    "    # return edgelists_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_retweeters_edgelist()\n",
    "create_liking_edgelist()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
