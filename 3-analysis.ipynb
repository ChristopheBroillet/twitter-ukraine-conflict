{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f3231ef-c5f9-4da3-b4cb-8e3f78739026",
   "metadata": {},
   "source": [
    "# Network component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c6a6bbe-959d-458d-b1f8-7c38d8b7f489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04444102-2c9b-4634-9d30-129033a13158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     user_id  author_id\n",
      "0                  159648236  454278875\n",
      "1                  272581313  454278875\n",
      "2                  400860401  454278875\n",
      "3                 1103560652  454278875\n",
      "4                   43412258  454278875\n",
      "...                      ...        ...\n",
      "5033373            325674737  554497503\n",
      "5033376           4191445095  554497503\n",
      "5033377            878977598  554497503\n",
      "5033378            481769384  554497503\n",
      "5033380  1462535282172084225  554497503\n",
      "\n",
      "[4466776 rows x 2 columns]\n",
      "len(G.nodes)=261\n",
      "len(G.edges)=328\n"
     ]
    }
   ],
   "source": [
    "# read all csv files from edgelists folder and save to edgelists_df\n",
    "edgelists_df = pd.concat([pd.read_csv(file) for file in Path(\"edgelists\").iterdir()], ignore_index=True)\n",
    "# drop duplicates in edgelists_df\n",
    "edgelists_df.drop_duplicates(inplace=True)\n",
    "print(edgelists_df)\n",
    "edgelists_graph_sample = edgelists_df['user_id'].unique()\n",
    "author_ids_sample = np.random.choice(edgelists_graph_sample, 200, replace=False)\n",
    "edgelists_df_sample = edgelists_df[edgelists_df['user_id'].isin(author_ids_sample)]\n",
    "\n",
    "G = nx.from_pandas_edgelist(edgelists_df_sample, source='user_id', target='author_id', create_using=nx.Graph())\n",
    "# print number of nodes in edgelists_graph_sample\n",
    "print(f\"{len(G.nodes)=}\")\n",
    "\n",
    "# print number of edges in edgelists_graph_sample\n",
    "print(f\"{len(G.edges)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1c300e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3320242092</td>\n",
       "      <td>851678533374136321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>849448663546040320</td>\n",
       "      <td>851678533374136321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>743981157881122816</td>\n",
       "      <td>851678533374136321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123719719851298816</td>\n",
       "      <td>851678533374136321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1523891821</td>\n",
       "      <td>851678533374136321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1281655655087198209</td>\n",
       "      <td>1430307870982107140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>703213345470550016</td>\n",
       "      <td>1430307870982107140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1309546727372922882</td>\n",
       "      <td>1430307870982107140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1425237620049776646</td>\n",
       "      <td>1430307870982107140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1157674198736744448</td>\n",
       "      <td>1430307870982107140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Source               Target\n",
       "0            3320242092   851678533374136321\n",
       "1    849448663546040320   851678533374136321\n",
       "2    743981157881122816   851678533374136321\n",
       "3   1123719719851298816   851678533374136321\n",
       "4            1523891821   851678533374136321\n",
       "..                  ...                  ...\n",
       "65  1281655655087198209  1430307870982107140\n",
       "66   703213345470550016  1430307870982107140\n",
       "67  1309546727372922882  1430307870982107140\n",
       "68  1425237620049776646  1430307870982107140\n",
       "69  1157674198736744448  1430307870982107140\n",
       "\n",
       "[70 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv from edgelistsSample folder\n",
    "edgelists_sample_df = pd.read_csv(\"edgelistsSample/edgelists_retweeters_sample.csv\")\n",
    "edgelists_sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e11a0a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(edgelists_sample_df, source='Source', target='Target', create_using=nx.Graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "760c50ae-def8-483b-95f5-ee7d247ace32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........There are 2 communities after passage 0\n",
      "..........There are 2 communities after passage 1\n",
      "..........There are 2 communities after passage 2\n"
     ]
    }
   ],
   "source": [
    "# Louvain implementation\n",
    "def louvain(G, npassage):\n",
    "    # Will contain the graph and the communities after each passage\n",
    "    data = {}\n",
    "    for i in range(npassage):\n",
    "        G, communities = louvain_step(G)\n",
    "        data[i] = (G, communities)\n",
    "        print(f\"There are {len(communities)} communities after passage {i}\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def louvain_step(G):\n",
    "    # Communities are stored in a dict\n",
    "    # Step 1: Initialization, start with each node being a single community\n",
    "    communities = {idx:[node] for idx, node in enumerate(G.nodes)}\n",
    "    \n",
    "    # TODO: ATM it is a fixed number of iteration, we need to find a way to\n",
    "    # Stop the iterations whenever the communities are not evolving anymore\n",
    "    for i in range(10):\n",
    "        print('.', flush=True, end='')\n",
    "        for node in G.nodes:\n",
    "            # Step 2: Remove node from its community\n",
    "            belong_to = get_community(node, communities)\n",
    "            communities[belong_to].remove(node)\n",
    "            if communities[belong_to] == []:\n",
    "                del communities[belong_to]\n",
    "\n",
    "            # Step 3: Insert the node in the community that maximizes the modularity\n",
    "            neighboring_communities = get_neighboring_communities(G, node, communities)\n",
    "            scores = [(neighbor_community, modularity(G, node, communities[neighbor_community])) for neighbor_community in neighboring_communities]\n",
    "            best_comm, best_score = max(scores, key=lambda x: x[1])\n",
    "            communities[best_comm].append(node)\n",
    "            \n",
    "#     return get_new_graph(G, communities), communities\n",
    "    return G, communities\n",
    "\n",
    "                \n",
    "def get_community(node, communities):\n",
    "    for idx, community in communities.items():\n",
    "        if node in community:\n",
    "            return idx\n",
    "    assert False, f\"Node {node} not found\"\n",
    "    \n",
    "    \n",
    "def get_neighboring_communities(G, node, communities):\n",
    "    neighboring_communities = []\n",
    "    for idx, community in communities.items():\n",
    "        for member in community:\n",
    "            # G[node] returns the neighbors of node\n",
    "            if member in [neighbor for neighbor in G[node]]:\n",
    "                neighboring_communities.append(idx)\n",
    "                continue\n",
    "    assert neighboring_communities != [], f\"No neighboring communities for node {node}\"\n",
    "    return neighboring_communities\n",
    "    \n",
    "\n",
    "def modularity(G, node, community):\n",
    "    shared_links = 0\n",
    "    deg_sum_community = 0\n",
    "    for member in community:\n",
    "        deg_sum_community += G.degree[member]\n",
    "        if member in [neighbor for neighbor in G[node]]:\n",
    "            # Shared links are counted in both direction: a -> b and b -> a\n",
    "            shared_links += 2\n",
    "    \n",
    "    return (1 / (2 * len(G.edges))) * (shared_links - (deg_sum_community*G.degree[node]/len(G.edges)))\n",
    "\n",
    "\n",
    "# def get_new_graph(old_graph, communities):\n",
    "# TODO: construct this method, IDK how to use the weighted edges in the modularity function/calculation\n",
    "    \n",
    "    \n",
    "data = louvain(G, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bdebf1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get last entry of data\n",
    "last_entry = data[len(data)-1]\n",
    "networkx_graph, communities_dict = last_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "635a3b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty dataframe with columns \"Id\",\"Label\", \"Community\", \"Is_author\"\n",
    "communities_df = pd.DataFrame(columns=[\"Id\",\"Label\", \"Community\", \"Is_author\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a751f3dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'Dataframe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\bao_l\\Projects\\twitter-ukraine-conflict\\3-analysis.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bao_l/Projects/twitter-ukraine-conflict/3-analysis.ipynb#ch0000015?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m communities_dict\u001b[39m.\u001b[39mitems():\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bao_l/Projects/twitter-ukraine-conflict/3-analysis.ipynb#ch0000015?line=3'>4</a>\u001b[0m     \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m value:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/bao_l/Projects/twitter-ukraine-conflict/3-analysis.ipynb#ch0000015?line=4'>5</a>\u001b[0m         communities_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([communities_df,pd\u001b[39m.\u001b[39;49mDataframe({\u001b[39m\"\u001b[39m\u001b[39mId\u001b[39m\u001b[39m\"\u001b[39m:idx, \u001b[39m\"\u001b[39m\u001b[39mLabel\u001b[39m\u001b[39m\"\u001b[39m:idx, \u001b[39m\"\u001b[39m\u001b[39mCommunity\u001b[39m\u001b[39m\"\u001b[39m:key, \u001b[39m\"\u001b[39m\u001b[39mIs_author\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39mFalse\u001b[39;00m})], ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\bao_l\\.virtualenvs\\twitter-ukraine-conflict-H_rK_fvr\\lib\\site-packages\\pandas\\__init__.py:261\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/bao_l/.virtualenvs/twitter-ukraine-conflict-H_rK_fvr/lib/site-packages/pandas/__init__.py?line=256'>257</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marrays\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m \u001b[39mimport\u001b[39;00m SparseArray \u001b[39mas\u001b[39;00m _SparseArray\n\u001b[0;32m    <a href='file:///c%3A/Users/bao_l/.virtualenvs/twitter-ukraine-conflict-H_rK_fvr/lib/site-packages/pandas/__init__.py?line=258'>259</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _SparseArray\n\u001b[1;32m--> <a href='file:///c%3A/Users/bao_l/.virtualenvs/twitter-ukraine-conflict-H_rK_fvr/lib/site-packages/pandas/__init__.py?line=260'>261</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodule \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpandas\u001b[39m\u001b[39m'\u001b[39m\u001b[39m has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'Dataframe'"
     ]
    }
   ],
   "source": [
    "# tranform communities_dict into a dataframe \n",
    "# key is the community, value is the Id\n",
    "for key, value in communities_dict.items():\n",
    "    for idx in value:\n",
    "        communities_df = pd.concat([communities_df, pd.DataFrame({\"Id\":idx, \"Label\":idx, \"Community\":key, \"Is_author\":False})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20e136aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Label</th>\n",
       "      <th>Community</th>\n",
       "      <th>Is_author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Id, Label, Community, Is_author]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communities_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bee368-d7bf-4f60-b364-2a73ad6e0d1b",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "- Sample by taking random author_id and take all edges connected to it\n",
    "- Implement from scratch community detection: Louvain (faster than Girvan)\n",
    "- Look at how to store the communities (edgelist or so)\n",
    "- Look at the caracteristics of the huge communities: what is the Tweet, who is the author, what are the hashtags etc...\n",
    "- Make profiles of users: press, random guy, famous guy, etc...\n",
    "- Look at outliers\n",
    "- Load communities to Gephi to vizualise them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6921534f-9fe6-4b47-be1e-38688abfdc41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e17df53156a1cd5dcd810416833fc7bc2978cb4c660ed625567caafd9f935baa"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('twitter-ukraine-conflict-H_rK_fvr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
