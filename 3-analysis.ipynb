{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f3231ef-c5f9-4da3-b4cb-8e3f78739026",
   "metadata": {},
   "source": [
    "# Network component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c6a6bbe-959d-458d-b1f8-7c38d8b7f489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "from tqdm import tqdm\n",
    "from itertools import tee\n",
    "\n",
    "Path.mkdir(Path(\"analysis\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e40a848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgelists = []\n",
    "\n",
    "for file in Path(\"edgelistsSample\").iterdir():\n",
    "    tmp_edgelist = pd.read_csv(file)\n",
    "    edgelists.append(tmp_edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6440684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graphs = []\n",
    "\n",
    "for edgelist in edgelists:\n",
    "    tmp_nx_graph = nx.from_pandas_edgelist(edgelist, source='Source', target='Target', create_using=nx.Graph())\n",
    "    nx.set_edge_attributes(tmp_nx_graph, 1, 'weight')\n",
    "    nx_graphs.append(tmp_nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1c300e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359703\n"
     ]
    }
   ],
   "source": [
    "# Read csv from edgelistsSample folder\n",
    "\n",
    "edgelists_sample_df = pd.read_csv(\"edgelistsSample/edgelists_any_sample.csv\")\n",
    "edgelists_sample_df\n",
    "G = nx.from_pandas_edgelist(edgelists_sample_df, source='Source', target='Target', create_using=nx.Graph())\n",
    "# Set all weights to 1\n",
    "nx.set_edge_attributes(G, 1, 'weight')\n",
    "print(len(G.nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e11a0a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After first passage: 43 communities\n",
      "After second passage: 33 communities\n"
     ]
    }
   ],
   "source": [
    "louvain_nx = community.louvain_partitions(G)\n",
    "first = next(louvain_nx)\n",
    "print(f\"After first passage: {len(first)} communities\")\n",
    "second = next(louvain_nx)\n",
    "print(f\"After second passage: {len(second)} communities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "760c50ae-def8-483b-95f5-ee7d247ace32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Louvain implementation\n",
    "def louvain(G, npassage):\n",
    "    # Will contain the graph and the communities after each passage\n",
    "    data = {}\n",
    "    for i in range(npassage):\n",
    "        print(f\"Passage {i}\", flush=True)\n",
    "        old_G, G, communities, get_community = louvain_step(G, G, i==0)\n",
    "        data[i] = (old_G, communities, get_community)\n",
    "        print(f\"There are {len(communities)} communities after passage {i}\", flush=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "def louvain_step(G, copy, is_first_passage):\n",
    "    # Step 1: Initialization, start with each node being a single community\n",
    "    communities = {idx: set([node]) for idx, node in enumerate(G.nodes)}\n",
    "    # To get direct access to the community (it speeds up a bit the algorithm)\n",
    "    get_community = {node: idx for idx, node in enumerate(G.nodes)}\n",
    "    # Used in the modularity computation\n",
    "    neighbors_sets = {node: set(G.neighbors(node)) for node in G.nodes}\n",
    "    m = len(G.edges)\n",
    "\n",
    "    # Sum the weights of the incident edges for all nodes inside a community, for all communities\n",
    "    # Separate first passage and other ones to speed up the algorithm\n",
    "    if is_first_passage:\n",
    "        sum_communities = {idx: sum(dict(G.degree(community)).values()) for idx, community in communities.items()}\n",
    "    else:\n",
    "        sum_communities = {idx: sum(dict(G.degree(community, 'weight')).values()) for idx, community in communities.items()}\n",
    "\n",
    "    # Fixed number of iterations\n",
    "    # TODO: change it?\n",
    "    for i in range(4):\n",
    "        print(f\"Iteration {i}\", flush=True)\n",
    "        for node in tqdm(G.nodes):\n",
    "            # Step 2: Remove node from its community\n",
    "            # TODO: make sure what we want to do if the node has no neighboring communities\n",
    "            neighboring_communities = get_neighboring_communities(G, node, get_community)\n",
    "            if neighboring_communities == set():\n",
    "                continue\n",
    "            belong_to = get_community[node]\n",
    "            communities[belong_to].remove(node)\n",
    "            sum_communities[belong_to] -= G.degree(node, 'weight')\n",
    "            if communities[belong_to] == set():\n",
    "                del communities[belong_to]\n",
    "                del sum_communities[belong_to]\n",
    "\n",
    "            # Step 3: Insert the node in the community that maximizes the modularity\n",
    "            scores = [\n",
    "                (neighbor_community, modularity_gain(G, node, communities[neighbor_community], sum_communities[neighbor_community], neighbors_sets[node], m, is_first_passage))\n",
    "                for neighbor_community in neighboring_communities\n",
    "            ]\n",
    "            best_community, best_score = max(scores, key=lambda x: x[1])\n",
    "            communities[best_community].add(node)\n",
    "            get_community[node] = best_community\n",
    "            sum_communities[best_community] += G.degree(node, 'weight')\n",
    "\n",
    "    return G, get_new_graph(G, communities, sum_communities, get_community), communities, get_community\n",
    "\n",
    "\n",
    "def get_neighboring_communities(G, node, get_community):\n",
    "    # Use a set to make sure a community only appear once\n",
    "    neighboring_communities = set()\n",
    "    for neighbor in G.neighbors(node):\n",
    "        if neighbor == node: continue\n",
    "        neighboring_communities.add(get_community[neighbor])\n",
    "\n",
    "    return neighboring_communities\n",
    "\n",
    "\n",
    "def modularity_gain(G, node, community, sum_community, neighbor_set, m, is_first_passage):\n",
    "    # Separate first passage and other ones to speed up the algorithm\n",
    "    if is_first_passage:\n",
    "        # Sum the weights of the edges from node into community nodes\n",
    "        # Using sets allow to use intersection()\n",
    "        sum_weights_node = len(neighbor_set.intersection(community))\n",
    "        right_member = (sum_community * G.degree[node]) / (2 * (m**2))\n",
    "    else:\n",
    "        # Sum the weights of the edges from node into community nodes\n",
    "        sum_weights_node = sum([G.get_edge_data(node, member)['weight'] for member in G.neighbors(node) if member in community])\n",
    "        right_member = (sum_community * G.degree(node, 'weight')) / (2 * (m**2))\n",
    "    # Compute modularity\n",
    "    left_member = sum_weights_node / (2 * m)\n",
    "    return left_member - right_member\n",
    "\n",
    "\n",
    "def get_new_graph(old_G, communities, sum_communities, get_community):\n",
    "    print(\"Construct new graph\", flush=True)\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(communities.keys())\n",
    "    for community in communities:\n",
    "        G.add_edge(community, community, weight=sum_communities[community])\n",
    "\n",
    "    for source, dest, weight_dict in old_G.edges(data=True):\n",
    "        community1 = get_community[source]\n",
    "        community2 = get_community[dest]\n",
    "        current_weight = G.get_edge_data(community1, community2, {'weight': 0})['weight']\n",
    "        # TODO: is this correct?\n",
    "        new_weight = current_weight + weight_dict['weight']\n",
    "        G.add_edge(community1, community2, weight=new_weight)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "213a5f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Louvain on 1/3\n",
      "Passage 0\n",
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718105/718105 [00:23<00:00, 30399.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 718105/718105 [00:22<00:00, 31263.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 718105/718105 [00:20<00:00, 34360.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 718105/718105 [00:21<00:00, 33417.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construct new graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 99 communities after passage 0\n",
      "Louvain on 2/3\n",
      "Passage 0\n",
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 696675/696675 [00:25<00:00, 27137.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 696675/696675 [00:29<00:00, 23603.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 696675/696675 [00:24<00:00, 28113.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 696675/696675 [00:26<00:00, 26761.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construct new graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 99 communities after passage 0\n",
      "Louvain on 3/3\n",
      "Passage 0\n",
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90487/90487 [00:04<00:00, 21708.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 90487/90487 [00:03<00:00, 27594.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 90487/90487 [00:03<00:00, 29844.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 90487/90487 [00:03<00:00, 29306.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construct new graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100 communities after passage 0\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for idx, G in enumerate(nx_graphs):\n",
    "    print(f\"Louvain on {idx+1}/{len(nx_graphs)}\", flush=True)\n",
    "    data = louvain(G, 1)\n",
    "    results.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "74e7e615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Community</th>\n",
       "      <th>Label</th>\n",
       "      <th>Is_author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1467218983405465603</td>\n",
       "      <td>1</td>\n",
       "      <td>1467218983405465603</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1369587782897831939</td>\n",
       "      <td>1</td>\n",
       "      <td>1369587782897831939</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1324887871484997633</td>\n",
       "      <td>1</td>\n",
       "      <td>1324887871484997633</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1641262814</td>\n",
       "      <td>1</td>\n",
       "      <td>1641262814</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1298969733174366209</td>\n",
       "      <td>1</td>\n",
       "      <td>1298969733174366209</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718100</th>\n",
       "      <td>2534082858</td>\n",
       "      <td>680777</td>\n",
       "      <td>2534082858</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718101</th>\n",
       "      <td>15918451</td>\n",
       "      <td>680777</td>\n",
       "      <td>15918451</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718102</th>\n",
       "      <td>348797527</td>\n",
       "      <td>680777</td>\n",
       "      <td>348797527</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718103</th>\n",
       "      <td>2886355146</td>\n",
       "      <td>680777</td>\n",
       "      <td>2886355146</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718104</th>\n",
       "      <td>17977180</td>\n",
       "      <td>680777</td>\n",
       "      <td>17977180</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>718105 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Id  Community                Label  Is_author\n",
       "0       1467218983405465603          1  1467218983405465603      False\n",
       "1       1369587782897831939          1  1369587782897831939      False\n",
       "2       1324887871484997633          1  1324887871484997633      False\n",
       "3                1641262814          1           1641262814      False\n",
       "4       1298969733174366209          1  1298969733174366209      False\n",
       "...                     ...        ...                  ...        ...\n",
       "718100           2534082858     680777           2534082858      False\n",
       "718101             15918451     680777             15918451      False\n",
       "718102            348797527     680777            348797527      False\n",
       "718103           2886355146     680777           2886355146      False\n",
       "718104             17977180     680777             17977180      False\n",
       "\n",
       "[718105 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = results[0][0]\n",
    "networkx_graph, communities_dict, get_community = test\n",
    "\n",
    "# convert get_community to pandas dataframe\n",
    "\n",
    "communities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa51ae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, result in enumerate(results):\n",
    "    first_entry = result[0]\n",
    "    networkx_graph, communities_dict, get_community = first_entry\n",
    "\n",
    "    communities_df = pd.DataFrame(get_community.items(), columns=['Id', 'Community'])\n",
    "    communities_df[\"Label\"] = communities_df[\"Id\"].map(lambda x: x)\n",
    "    communities_df[\"Is_author\"] = False\n",
    "\n",
    "    # communities_df = pd.DataFrame(columns=[\"Id\",\"Label\", \"Community\", \"Is_author\"])\n",
    "\n",
    "    # communities_df = pd.DataFrame(get_community.items(), columns=['Id', 'community'])\n",
    "\n",
    "    # for key, value in communities_dict.items():\n",
    "    #     for idx in value:\n",
    "    #         communities_df = pd.concat([communities_df, pd.DataFrame({\"Id\":idx, \"Label\":idx, \"Community\":key, \"Is_author\":False}, index=[0])], ignore_index=True)\n",
    "    \n",
    "    communities_df.loc[communities_df['Id'].isin(edgelists[idx]['Target'].unique()), \"Is_author\"] = True\n",
    "\n",
    "    communities_df.to_csv(f\"analysis/communities_df_{idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bee368-d7bf-4f60-b364-2a73ad6e0d1b",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "- Sample by taking random author_id and take all edges connected to it\n",
    "- Implement from scratch community detection: Louvain (faster than Girvan)\n",
    "- Look at how to store the communities (edgelist or so)\n",
    "- Look at the caracteristics of the huge communities: what is the Tweet, who is the author, what are the hashtags etc...\n",
    "- Make profiles of users: press, random guy, famous guy, etc...\n",
    "- Look at outliers\n",
    "- Load communities to Gephi to vizualise them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6921534f-9fe6-4b47-be1e-38688abfdc41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e17df53156a1cd5dcd810416833fc7bc2978cb4c660ed625567caafd9f935baa"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
