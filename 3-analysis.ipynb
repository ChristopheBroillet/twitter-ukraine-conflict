{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f3231ef-c5f9-4da3-b4cb-8e3f78739026",
   "metadata": {},
   "source": [
    "# Network component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c6a6bbe-959d-458d-b1f8-7c38d8b7f489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "from numba import jit\n",
    "from tqdm import tqdm\n",
    "from itertools import tee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04444102-2c9b-4634-9d30-129033a13158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     user_id           author_id\n",
      "0                 4718799509  755067744333271040\n",
      "1        1239540883080581120  755067744333271040\n",
      "2                  495339130  755067744333271040\n",
      "3                  198514083  755067744333271040\n",
      "4        1488576875744137218  755067744333271040\n",
      "...                      ...                 ...\n",
      "5033369  1165006575939018759           106927705\n",
      "5033373             88566817          2389823918\n",
      "5033375           2389823918          2389823918\n",
      "5033378           1468140559            54168532\n",
      "5033380  1161924136383369216            54168532\n",
      "\n",
      "[4466776 rows x 2 columns]\n",
      "len(G.nodes)=20316\n",
      "len(G.edges)=31779\n"
     ]
    }
   ],
   "source": [
    "# # read all csv files from edgelists folder and save to edgelists_df\n",
    "# edgelists_df = pd.concat([pd.read_csv(file) for file in Path(\"edgelists\").iterdir()], ignore_index=True)\n",
    "# # drop duplicates in edgelists_df\n",
    "# edgelists_df.drop_duplicates(inplace=True)\n",
    "# print(edgelists_df)\n",
    "# edgelists_graph_sample = edgelists_df['user_id'].unique()\n",
    "# author_ids_sample = np.random.choice(edgelists_graph_sample, 20000, replace=False)\n",
    "# edgelists_df_sample = edgelists_df[edgelists_df['user_id'].isin(author_ids_sample)]\n",
    "\n",
    "# G = nx.from_pandas_edgelist(edgelists_df_sample, source='user_id', target='author_id', create_using=nx.Graph())\n",
    "# # print number of nodes in edgelists_graph_sample\n",
    "# print(f\"{len(G.nodes)=}\")\n",
    "\n",
    "# # print number of edges in edgelists_graph_sample\n",
    "# print(f\"{len(G.edges)=}\")\n",
    "# nx.set_edge_attributes(G, 1, 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1c300e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3672\n"
     ]
    }
   ],
   "source": [
    "# read csv from edgelistsSample folder\n",
    "edgelists_sample_df = pd.read_csv(\"edgelistsSample/edgelists_any_sample.csv\")\n",
    "edgelists_sample_df\n",
    "G = nx.from_pandas_edgelist(edgelists_sample_df, source='Source', target='Target', create_using=nx.Graph())\n",
    "print(len(G.nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e11a0a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After first passage: 2 communities\n"
     ]
    }
   ],
   "source": [
    "louvain_nx = community.louvain_partitions(G)\n",
    "first = next(louvain_nx)\n",
    "print(f\"After first passage: {len(first)} communities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "760c50ae-def8-483b-95f5-ee7d247ace32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passage 0\n",
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 3672/3672 [00:05<00:00, 625.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 3672/3672 [00:08<00:00, 410.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 communities after passage 0\n",
      "Passage 1\n",
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 25040.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 30174.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 communities after passage 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Louvain implementation\n",
    "def louvain(G, npassage):\n",
    "    # Ensure there is a 'weight' label\n",
    "    nx.set_edge_attributes(G, 1, 'weight')\n",
    "\n",
    "    # Will contain the graph and the communities after each passage\n",
    "    data = {}\n",
    "    for i in range(npassage):\n",
    "        print(f\"Passage {i}\")\n",
    "        G, communities = louvain_step(G)\n",
    "        data[i] = (G, communities)\n",
    "        print(f\"There are {len(communities)} communities after passage {i}\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def louvain_step(G):\n",
    "    # Communities are stored in a dict\n",
    "    # Step 1: Initialization, start with each node being a single community\n",
    "    communities = {idx:[node] for idx, node in enumerate(G.nodes)}\n",
    "    m = len(G.edges)\n",
    "\n",
    "    # TODO: ATM it is a fixed number of iteration, we need to find a way to\n",
    "    # Stop the iterations whenever the communities are not evolving anymore\n",
    "    for i in range(2):\n",
    "        print(f\"Iteration {i}\")\n",
    "        for node in tqdm(G.nodes()):\n",
    "            # Step 2: Remove node from its community\n",
    "            belong_to = get_community(node, communities)\n",
    "            communities[belong_to].remove(node)\n",
    "            if communities[belong_to] == []:\n",
    "                del communities[belong_to]\n",
    "\n",
    "            # Step 3: Insert the node in the community that maximizes the modularity\n",
    "            neighboring_communities = get_neighboring_communities(G, node, communities)\n",
    "            scores = [(neighbor_community, modularity_gain(G, node, communities[neighbor_community], m)) for neighbor_community in neighboring_communities]\n",
    "            best_comm, best_score = max(scores, key=lambda x: x[1])\n",
    "            communities[best_comm].append(node)\n",
    "    return get_new_graph(G, communities), communities\n",
    "\n",
    "\n",
    "def get_community(node, communities):\n",
    "    for idx, community in communities.items():\n",
    "        if node in community:\n",
    "            return idx\n",
    "    assert False, f\"Node {node} not found\"\n",
    "\n",
    "\n",
    "def get_neighboring_communities(G, node, communities):\n",
    "    # Use a set to make sure a community only appear once\n",
    "    neighboring_communities = set()\n",
    "    for neighbor in G[node]:\n",
    "        if neighbor == node: continue\n",
    "        neighboring_communities.add(get_community(neighbor, communities))\n",
    "\n",
    "    assert neighboring_communities != set(), f\"No neighboring communities for node {node}\"\n",
    "    return neighboring_communities\n",
    "\n",
    "\n",
    "def modularity_gain(G, node, community, m):\n",
    "    # Sum the weights of the edges from node into community nodes\n",
    "    sum_weights_node = sum([G.get_edge_data(node, member)['weight'] for member in community if member in G.neighbors(node)])\n",
    "    # Sum the weights of the incident edges for all nodes in community\n",
    "    sum_community = sum([weight for _node, weight in G.degree(community, 'weight')])\n",
    "    # Compute modularity\n",
    "    left_member = sum_weights_node / (2 * m)\n",
    "    right_member = (sum_community * G.degree(node, 'weight')) / (2 * (m**2))\n",
    "    return left_member - right_member\n",
    "\n",
    "\n",
    "def get_new_graph(old_G, communities):\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(communities.keys())\n",
    "    for idx, community in communities.items():\n",
    "        # Sum the weights of the incident edges for all nodes in community\n",
    "        sum_community = sum([weight for node, weight in G.degree(community, 'weight')])\n",
    "        G.add_edge(idx, idx, weight=sum_community)\n",
    "    between_edge = 0\n",
    "    for (idx1, community1), (idx2, community2) in pairwise(communities.items()):\n",
    "        for place, node1 in enumerate(community1):\n",
    "            for node2 in community2[place:]:\n",
    "                if G.get_edge_data(node1, node2) is not None:\n",
    "                    between_edge += G.get_edge_data(node1, node2)['weight']\n",
    "        G.add_edge(idx1, idx2, weight=between_edge)\n",
    "    return G\n",
    "\n",
    "\n",
    "# pairwise() from Itertools Recipes\n",
    "# To iterate pairwise keys in a dict, from Stackoverflow\n",
    "# https://stackoverflow.com/questions/37010754/python-loop-dictionary-two-keys-at-a-time\n",
    "def pairwise(iterable):\n",
    "    \"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\n",
    "    a, b = tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)\n",
    "\n",
    "\n",
    "data = louvain(G, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bdebf1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get last entry of data\n",
    "last_entry = data[len(data)-1]\n",
    "networkx_graph, communities_dict = last_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a751f3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_df = pd.DataFrame(columns=[\"Id\",\"Label\", \"Community\", \"Is_author\"])\n",
    "\n",
    "# tranform communities_dict into a dataframe \n",
    "# key is the community, value is the Id\n",
    "for key, value in communities_dict.items():\n",
    "    for idx in value:\n",
    "        communities_df = pd.concat([communities_df, pd.DataFrame({\"Id\":idx, \"Label\":idx, \"Community\":key, \"Is_author\":False}, index=[0])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5cd13212",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_df.loc[communities_df['Id'].isin(edgelists_sample_df['Target'].unique()), \"Is_author\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "70fc76bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Label</th>\n",
       "      <th>Community</th>\n",
       "      <th>Is_author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3320242092</td>\n",
       "      <td>3320242092</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>851678533374136321</td>\n",
       "      <td>851678533374136321</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>849448663546040320</td>\n",
       "      <td>849448663546040320</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>743981157881122816</td>\n",
       "      <td>743981157881122816</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1123719719851298816</td>\n",
       "      <td>1123719719851298816</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1430307870982107140</td>\n",
       "      <td>1430307870982107140</td>\n",
       "      <td>66</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>703213345470550016</td>\n",
       "      <td>703213345470550016</td>\n",
       "      <td>66</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1309546727372922882</td>\n",
       "      <td>1309546727372922882</td>\n",
       "      <td>66</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1425237620049776646</td>\n",
       "      <td>1425237620049776646</td>\n",
       "      <td>66</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1157674198736744448</td>\n",
       "      <td>1157674198736744448</td>\n",
       "      <td>66</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Id                Label Community Is_author\n",
       "0            3320242092           3320242092         1     False\n",
       "1    851678533374136321   851678533374136321         1      True\n",
       "2    849448663546040320   849448663546040320         1     False\n",
       "3    743981157881122816   743981157881122816         1     False\n",
       "4   1123719719851298816  1123719719851298816         1     False\n",
       "..                  ...                  ...       ...       ...\n",
       "66  1430307870982107140  1430307870982107140        66      True\n",
       "67   703213345470550016   703213345470550016        66     False\n",
       "68  1309546727372922882  1309546727372922882        66     False\n",
       "69  1425237620049776646  1425237620049776646        66     False\n",
       "70  1157674198736744448  1157674198736744448        66     False\n",
       "\n",
       "[71 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "34d09d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv, ignore index\n",
    "communities_df.to_csv(\"communities_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bee368-d7bf-4f60-b364-2a73ad6e0d1b",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "- Sample by taking random author_id and take all edges connected to it\n",
    "- Implement from scratch community detection: Louvain (faster than Girvan)\n",
    "- Look at how to store the communities (edgelist or so)\n",
    "- Look at the caracteristics of the huge communities: what is the Tweet, who is the author, what are the hashtags etc...\n",
    "- Make profiles of users: press, random guy, famous guy, etc...\n",
    "- Look at outliers\n",
    "- Load communities to Gephi to vizualise them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6921534f-9fe6-4b47-be1e-38688abfdc41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e17df53156a1cd5dcd810416833fc7bc2978cb4c660ed625567caafd9f935baa"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
